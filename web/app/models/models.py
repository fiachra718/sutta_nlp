# models.py
from pydantic import BaseModel, Field
from datetime import datetime
from typing import List, Literal, Optional, ClassVar
from pydantic import BaseModel, Field, field_validator, model_validator
from hashlib import md5
import unicodedata
import json
from .manager import Manager


CANDIDATE_COLUMNS = ("id", "source_identifier", "source_verse_num", "text", "text_hash", "entities")
TRAINING_COLUMNS = ("id", "text", "text_hash", "spans", "spans_hash", "source", "from_file", "created_at")


def _candidate_row_processor(row):
    data = {col: row.get(col) for col in CANDIDATE_COLUMNS}
    data["entities"] = data.get("entities") or []
    return data


def _training_row_processor(row):
    data = {col: row.get(col) for col in TRAINING_COLUMNS}
    data["spans"] = data.get("spans") or []
    return data


Label = Literal["PERSON", "GPE", "LOC", "NORP", "EVENT"]


class SuttaVerse(BaseModel):
    identifier: str          # e.g., "mn.001.than"
    verse_num: int
    text: str                # NFC normalized; what you render & annotate
    text_hash: str           # md5 of normalized text


class Span(BaseModel):
    start: int = Field(ge=0)
    end: int = Field(gt=0)
    label: Label

    @model_validator(mode="after")
    def check_offsets(self):
        if self.end <= self.start:
            raise ValueError("span.end must be > span.start")
        if self.start < 0:
            raise ValueError("span start must be > 0")
        return self


class CandidateDoc(BaseModel):
    id: Optional[int] = None                    # autogenerated by Postgres
    source_identifier: Optional[str] = None
    source_verse_num: Optional[int] = None
    text: str                                   # exact review text (same as SuttaVerse.text)
    text_hash: Optional[str] = None                   # gen md5Sum
    entities: List[tuple[str, str]] = Field(default_factory=list)

    objects: ClassVar[Manager] = Manager(
        table="candidates",
        columns=CANDIDATE_COLUMNS,
        row_processor=_candidate_row_processor,
    )

    @model_validator(mode="before")
    @classmethod
    def normalize_and_hash(cls, data):
        if not isinstance(data, dict):
            return data
        txt = data.get("text", "")
        # Normalize once so offsets/lengths are stable across pipeline
        norm = unicodedata.normalize("NFC", txt) if isinstance(txt, str) else txt
        if isinstance(norm, str):
            data = {**data, "text": norm}
            if not data.get("text_hash"):
                data["text_hash"] = md5(norm.encode("utf-8")).hexdigest()
        return data

    @model_validator(mode="after")
    def check_hash(self):
        # If caller passed a hash, ensure it matches the normalized text
        expected = md5(self.text.encode("utf-8")).hexdigest()
        if self.text_hash and self.text_hash != expected:
            raise ValueError("text_hash does not match normalized text")
        # ensure entities are exactly 2-tuples
        for lab, txt in self.entities:
            if not isinstance(lab, str) or not isinstance(txt, str):
                raise ValueError("entities must be (label, text) pairs of strings")
        return self


class TrainingDoc(BaseModel):
    id: Optional[str] = None
    text: str
    text_hash: Optional[str] = None
    spans: list[Span]        # human-reviewed, overlap-free, slice-checked
    spans_hash: Optional[str] = None
    source: Optional[str] | None = None
    from_file: Optional[str] | None = None
    objects: ClassVar[Manager] = Manager(
        table="gold_training",
        columns=TRAINING_COLUMNS,
        row_processor=_training_row_processor,
    )


    def finalize(self):
        """Fill in derived fields (hashes, timestamp) without being a control freak."""
        txt = unicodedata.normalize("NFC", self.text)
        self.text = txt
        self.text_hash = md5(txt.encode("utf-8")).hexdigest()
        payload = json.dumps(
            [s.model_dump() for s in sorted(self.spans, key=lambda x: (x.start, x.end, x.label))],
            separators=(",", ":"),
            ensure_ascii=False,
        )
        if not self.created_at:
            self.created_at = datetime.utcnow()
        return self


# sanity check
if __name__ == "__main__":
    # try loading a candidate doc
    data = {"text":"I heard thus. Once the Blessed One, while wandering in the Kosala country",
            "entities": [["PERSON", "Blessed One"], ["GPE", "Kosala"]] }
    

    doc = CandidateDoc.model_validate(data)
    print(doc.model_dump())


    # try loading a training doc
    record = {
            "text": "This Makkhali Gosala...",
        "spans": [
            {"start": 5, "end": 20, "label": "PERSON", "text": "Makkhali Gosala"}
        ]
    }
    doc = TrainingDoc.model_validate(record)
    print(doc.spans[0].label)   # PERSON
    print(doc.model_dump())   # prints record + hash
